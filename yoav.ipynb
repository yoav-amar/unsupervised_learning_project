{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa454178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kmodes in ./.venv/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./.venv/lib/python3.10/site-packages (from kmodes) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in ./.venv/lib/python3.10/site-packages (from kmodes) (1.13.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.10/site-packages (from kmodes) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in ./.venv/lib/python3.10/site-packages (from kmodes) (1.6.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=0.22.0->kmodes) (3.6.0)\n",
      "Collecting gower\n",
      "  Downloading gower-0.1.2-py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from gower) (1.26.4)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from gower) (1.13.1)\n",
      "Installing collected packages: gower\n",
      "Successfully installed gower-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install kmodes\n",
    "!pip install gower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef784cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "df = X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae109ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48842, 14)\n",
      "(45222, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>77516</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>83311</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>215646</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>234721</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>338409</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45217</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>245211</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45218</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>215419</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>374983</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45220</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>83891</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45221</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>182148</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45222 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0       39          0   77516          0             13               0   \n",
       "1       50          1   83311          0             13               1   \n",
       "2       38          2  215646          1              9               2   \n",
       "3       53          2  234721          2              7               1   \n",
       "4       28          2  338409          0             13               1   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "45217   33          2  245211          0             13               0   \n",
       "45218   39          2  215419          0             13               2   \n",
       "45219   38          2  374983          0             13               1   \n",
       "45220   44          2   83891          0             13               2   \n",
       "45221   35          5  182148          0             13               1   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               0             0     0    0          2174             0   \n",
       "1               1             1     0    0             0             0   \n",
       "2               2             0     0    0             0             0   \n",
       "3               2             1     1    0             0             0   \n",
       "4               3             2     1    1             0             0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "45217           3             3     0    0             0             0   \n",
       "45218           3             0     0    1             0             0   \n",
       "45219           3             1     0    0             0             0   \n",
       "45220           0             3     2    0          5455             0   \n",
       "45221           1             1     0    0             0             0   \n",
       "\n",
       "       hours-per-week  native-country  \n",
       "0                  40               0  \n",
       "1                  13               0  \n",
       "2                  40               0  \n",
       "3                  40               0  \n",
       "4                  40               1  \n",
       "...               ...             ...  \n",
       "45217              40               0  \n",
       "45218              36               0  \n",
       "45219              50               0  \n",
       "45220              40               0  \n",
       "45221              60               0  \n",
       "\n",
       "[45222 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "df: pd.DataFrame = X\n",
    "\n",
    "print(df.shape)\n",
    "df = df[~df.eq(\"?\").any(axis=1)]\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.to_csv(\"adults.csv\", index=False)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "\n",
    "# df = pd.get_dummies(df, columns=categorical_cols)\n",
    "\n",
    "# cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "categorical_indexes = [df.columns.get_loc(col) for col in categorical_cols]\n",
    "\n",
    "categorical_indexes\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col], _ = pd.factorize(df[col])\n",
    "    \n",
    "# df[numerical_cols]  = MinMaxScaler().fit_transform(df[numerical_cols])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503dcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon=0.05, min_sample=2, number_of_labels=1037, score_with_bad=0.32259753, 0.7163484692573547\n",
      "epsilon=0.1, min_sample=8 classification is bad\n",
      "epsilon=0.1, min_sample=8, score_with_bad=0.20074089\n",
      "epsilon=0.1, min_sample=14 classification is bad\n",
      "epsilon=0.1, min_sample=14, score_with_bad=0.19211902\n",
      "epsilon=0.1, min_sample=18 classification is bad\n",
      "epsilon=0.1, min_sample=18, score_with_bad=0.18652338\n",
      "epsilon=0.1, min_sample=20 classification is bad\n",
      "epsilon=0.1, min_sample=20, score_with_bad=0.18560497\n",
      "epsilon=0.1, min_sample=22 classification is bad\n",
      "epsilon=0.1, min_sample=22, score_with_bad=0.18380935\n",
      "epsilon=0.1, min_sample=24 classification is bad\n",
      "epsilon=0.1, min_sample=24, score_with_bad=0.1824984\n",
      "epsilon=0.1, min_sample=26 classification is bad\n",
      "epsilon=0.1, min_sample=26, score_with_bad=0.1810911\n",
      "epsilon=0.1, min_sample=28 classification is bad\n",
      "epsilon=0.1, min_sample=28, score_with_bad=0.17873658\n",
      "epsilon=0.1, min_sample=30 classification is bad\n",
      "epsilon=0.1, min_sample=30, score_with_bad=0.17777006\n",
      "epsilon=0.1, min_sample=32 classification is bad\n",
      "epsilon=0.1, min_sample=32, score_with_bad=0.17708014\n",
      "epsilon=0.1, min_sample=34 classification is bad\n",
      "epsilon=0.1, min_sample=34, score_with_bad=0.17633067\n",
      "epsilon=0.1, min_sample=36 classification is bad\n",
      "epsilon=0.1, min_sample=36, score_with_bad=0.17486529\n",
      "epsilon=0.1, min_sample=38 classification is bad\n",
      "epsilon=0.1, min_sample=38, score_with_bad=0.17382349\n",
      "epsilon=0.1, min_sample=40 classification is bad\n",
      "epsilon=0.1, min_sample=40, score_with_bad=0.17257014\n",
      "epsilon=0.1, min_sample=42 classification is bad\n",
      "epsilon=0.1, min_sample=42, score_with_bad=0.17138831\n",
      "epsilon=0.1, min_sample=44 classification is bad\n",
      "epsilon=0.1, min_sample=44, score_with_bad=0.17034784\n",
      "epsilon=0.1, min_sample=46 classification is bad\n",
      "epsilon=0.1, min_sample=46, score_with_bad=0.16862242\n",
      "epsilon=0.1, min_sample=48 classification is bad\n",
      "epsilon=0.1, min_sample=48, score_with_bad=0.16761217\n",
      "epsilon=0.1, min_sample=50 classification is bad\n",
      "epsilon=0.1, min_sample=50, score_with_bad=0.16576444\n",
      "epsilon=0.1, min_sample=52 classification is bad\n",
      "epsilon=0.1, min_sample=52, score_with_bad=0.16505627\n",
      "epsilon=0.1, min_sample=54 classification is bad\n",
      "epsilon=0.1, min_sample=54, score_with_bad=0.1635565\n",
      "epsilon=0.1, min_sample=56 classification is bad\n",
      "epsilon=0.1, min_sample=56, score_with_bad=0.16170628\n",
      "epsilon=0.1, min_sample=58 classification is bad\n",
      "epsilon=0.1, min_sample=58, score_with_bad=0.16110986\n",
      "epsilon=0.1, min_sample=60 classification is bad\n",
      "epsilon=0.1, min_sample=60, score_with_bad=0.16038568\n",
      "epsilon=0.1, min_sample=62 classification is bad\n",
      "epsilon=0.1, min_sample=62, score_with_bad=0.15927686\n",
      "epsilon=0.1, min_sample=64 classification is bad\n",
      "epsilon=0.1, min_sample=64, score_with_bad=0.15865624\n",
      "epsilon=0.1, min_sample=66 classification is bad\n",
      "epsilon=0.1, min_sample=66, score_with_bad=0.15542193\n",
      "epsilon=0.1, min_sample=68 classification is bad\n",
      "epsilon=0.1, min_sample=68, score_with_bad=0.15403129\n",
      "epsilon=0.1, min_sample=70 classification is bad\n",
      "epsilon=0.1, min_sample=70, score_with_bad=0.15300937\n",
      "epsilon=0.1, min_sample=72 classification is bad\n",
      "epsilon=0.1, min_sample=72, score_with_bad=0.15227985\n",
      "epsilon=0.1, min_sample=74 classification is bad\n",
      "epsilon=0.1, min_sample=74, score_with_bad=0.15101111\n",
      "epsilon=0.1, min_sample=76 classification is bad\n",
      "epsilon=0.1, min_sample=76, score_with_bad=0.149757\n",
      "epsilon=0.1, min_sample=78 classification is bad\n",
      "epsilon=0.1, min_sample=78, score_with_bad=0.14956477\n",
      "epsilon=0.15000000000000002, min_sample=10 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=10, score_with_bad=0.23341082\n",
      "epsilon=0.15000000000000002, min_sample=12 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=12, score_with_bad=0.23198798\n",
      "epsilon=0.15000000000000002, min_sample=14 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=14, score_with_bad=0.2307519\n",
      "epsilon=0.15000000000000002, min_sample=16 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=16, score_with_bad=0.22993623\n",
      "epsilon=0.15000000000000002, min_sample=18 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=18, score_with_bad=0.22982627\n",
      "epsilon=0.15000000000000002, min_sample=20 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=20, score_with_bad=0.22905928\n",
      "epsilon=0.15000000000000002, min_sample=22 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=22, score_with_bad=0.22795999\n",
      "epsilon=0.15000000000000002, min_sample=24 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=24, score_with_bad=0.2274581\n",
      "epsilon=0.15000000000000002, min_sample=26 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=26, score_with_bad=0.22565237\n",
      "epsilon=0.15000000000000002, min_sample=28 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=28, score_with_bad=0.22430198\n",
      "epsilon=0.15000000000000002, min_sample=30 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=30, score_with_bad=0.22288732\n",
      "epsilon=0.15000000000000002, min_sample=32 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=32, score_with_bad=0.22187614\n",
      "epsilon=0.15000000000000002, min_sample=34 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=34, score_with_bad=0.22091854\n",
      "epsilon=0.15000000000000002, min_sample=36 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=36, score_with_bad=0.22032647\n",
      "epsilon=0.15000000000000002, min_sample=38 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=38, score_with_bad=0.21950479\n",
      "epsilon=0.15000000000000002, min_sample=40 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=40, score_with_bad=0.21869883\n",
      "epsilon=0.15000000000000002, min_sample=42 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=42, score_with_bad=0.21760742\n",
      "epsilon=0.15000000000000002, min_sample=44 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=44, score_with_bad=0.21696109\n",
      "epsilon=0.15000000000000002, min_sample=46 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=46, score_with_bad=0.21618406\n",
      "epsilon=0.15000000000000002, min_sample=48 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=48, score_with_bad=0.21546365\n",
      "epsilon=0.15000000000000002, min_sample=50 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=50, score_with_bad=0.2149122\n",
      "epsilon=0.15000000000000002, min_sample=52 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=52, score_with_bad=0.21440269\n",
      "epsilon=0.15000000000000002, min_sample=54 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=54, score_with_bad=0.2136853\n",
      "epsilon=0.15000000000000002, min_sample=56 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=56, score_with_bad=0.21253271\n",
      "epsilon=0.15000000000000002, min_sample=58 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=58, score_with_bad=0.21142903\n",
      "epsilon=0.15000000000000002, min_sample=60 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=60, score_with_bad=0.21099693\n",
      "epsilon=0.15000000000000002, min_sample=62 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=62, score_with_bad=0.2099536\n",
      "epsilon=0.15000000000000002, min_sample=64 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=64, score_with_bad=0.20959124\n",
      "epsilon=0.15000000000000002, min_sample=66 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=66, score_with_bad=0.20907953\n",
      "epsilon=0.15000000000000002, min_sample=68 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=68, score_with_bad=0.20812006\n",
      "epsilon=0.15000000000000002, min_sample=70 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=70, score_with_bad=0.20702302\n",
      "epsilon=0.15000000000000002, min_sample=72 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=72, score_with_bad=0.20628792\n",
      "epsilon=0.15000000000000002, min_sample=74 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=74, score_with_bad=0.20481096\n",
      "epsilon=0.15000000000000002, min_sample=76 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=76, score_with_bad=0.20345883\n",
      "epsilon=0.15000000000000002, min_sample=78 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=78, score_with_bad=0.20284618\n",
      "epsilon=0.15000000000000002, min_sample=80 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=80, score_with_bad=0.20270714\n",
      "epsilon=0.15000000000000002, min_sample=82 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=82, score_with_bad=0.20242137\n",
      "epsilon=0.15000000000000002, min_sample=84 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=84, score_with_bad=0.2025718\n",
      "epsilon=0.15000000000000002, min_sample=86 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=86, score_with_bad=0.20165339\n",
      "epsilon=0.15000000000000002, min_sample=88 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=88, score_with_bad=0.20033632\n",
      "epsilon=0.15000000000000002, min_sample=90 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=90, score_with_bad=0.19967672\n",
      "epsilon=0.15000000000000002, min_sample=92 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=92, score_with_bad=0.19915545\n",
      "epsilon=0.15000000000000002, min_sample=94 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=94, score_with_bad=0.19836026\n",
      "epsilon=0.15000000000000002, min_sample=96 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=96, score_with_bad=0.19796345\n",
      "epsilon=0.15000000000000002, min_sample=98 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=98, score_with_bad=0.19699138\n",
      "epsilon=0.15000000000000002, min_sample=100 classification is bad\n",
      "epsilon=0.15000000000000002, min_sample=100, score_with_bad=0.19671349\n",
      "epsilon=0.2, min_sample=4 classification is bad\n",
      "epsilon=0.2, min_sample=4, score_with_bad=0.28861606\n",
      "epsilon=0.2, min_sample=6 classification is bad\n",
      "epsilon=0.2, min_sample=6, score_with_bad=0.28855497\n",
      "epsilon=0.2, min_sample=8 classification is bad\n",
      "epsilon=0.2, min_sample=8, score_with_bad=0.28892577\n",
      "epsilon=0.2, min_sample=10 classification is bad\n",
      "epsilon=0.2, min_sample=10, score_with_bad=0.28799665\n",
      "epsilon=0.2, min_sample=12 classification is bad\n",
      "epsilon=0.2, min_sample=12, score_with_bad=0.28332487\n",
      "epsilon=0.2, min_sample=14 classification is bad\n",
      "epsilon=0.2, min_sample=14, score_with_bad=0.28396645\n",
      "epsilon=0.2, min_sample=16 classification is bad\n",
      "epsilon=0.2, min_sample=16, score_with_bad=0.2843428\n",
      "epsilon=0.2, min_sample=18 classification is bad\n",
      "epsilon=0.2, min_sample=18, score_with_bad=0.28166735\n",
      "epsilon=0.2, min_sample=20 classification is bad\n",
      "epsilon=0.2, min_sample=20, score_with_bad=0.28166735\n",
      "epsilon=0.2, min_sample=22 classification is bad\n",
      "epsilon=0.2, min_sample=22, score_with_bad=0.28166735\n",
      "epsilon=0.2, min_sample=24 classification is bad\n",
      "epsilon=0.2, min_sample=24, score_with_bad=0.28091443\n",
      "epsilon=0.2, min_sample=26 classification is bad\n",
      "epsilon=0.2, min_sample=26, score_with_bad=0.2810972\n",
      "epsilon=0.2, min_sample=28 classification is bad\n",
      "epsilon=0.2, min_sample=28, score_with_bad=0.2810972\n",
      "epsilon=0.2, min_sample=30 classification is bad\n",
      "epsilon=0.2, min_sample=30, score_with_bad=0.28084597\n",
      "epsilon=0.2, min_sample=32 classification is bad\n",
      "epsilon=0.2, min_sample=32, score_with_bad=0.28080013\n",
      "epsilon=0.2, min_sample=34 classification is bad\n",
      "epsilon=0.2, min_sample=34, score_with_bad=0.28038388\n",
      "epsilon=0.2, min_sample=36 classification is bad\n",
      "epsilon=0.2, min_sample=36, score_with_bad=0.2781676\n",
      "epsilon=0.2, min_sample=38 classification is bad\n",
      "epsilon=0.2, min_sample=38, score_with_bad=0.27864856\n",
      "epsilon=0.2, min_sample=40 classification is bad\n",
      "epsilon=0.2, min_sample=40, score_with_bad=0.27773905\n",
      "epsilon=0.2, min_sample=42 classification is bad\n",
      "epsilon=0.2, min_sample=42, score_with_bad=0.27773905\n",
      "epsilon=0.2, min_sample=44 classification is bad\n",
      "epsilon=0.2, min_sample=44, score_with_bad=0.27684262\n",
      "epsilon=0.2, min_sample=46 classification is bad\n",
      "epsilon=0.2, min_sample=46, score_with_bad=0.27677384\n",
      "epsilon=0.2, min_sample=48 classification is bad\n",
      "epsilon=0.2, min_sample=48, score_with_bad=0.27616033\n",
      "epsilon=0.2, min_sample=50 classification is bad\n",
      "epsilon=0.2, min_sample=50, score_with_bad=0.27828175\n",
      "epsilon=0.2, min_sample=52 classification is bad\n",
      "epsilon=0.2, min_sample=52, score_with_bad=0.27865398\n",
      "epsilon=0.2, min_sample=54 classification is bad\n",
      "epsilon=0.2, min_sample=54, score_with_bad=0.27865398\n",
      "epsilon=0.2, min_sample=56 classification is bad\n",
      "epsilon=0.2, min_sample=56, score_with_bad=0.2783369\n",
      "epsilon=0.2, min_sample=58 classification is bad\n",
      "epsilon=0.2, min_sample=58, score_with_bad=0.27806997\n",
      "epsilon=0.2, min_sample=60 classification is bad\n",
      "epsilon=0.2, min_sample=60, score_with_bad=0.27806997\n",
      "epsilon=0.2, min_sample=62 classification is bad\n",
      "epsilon=0.2, min_sample=62, score_with_bad=0.27806997\n",
      "epsilon=0.2, min_sample=64 classification is bad\n",
      "epsilon=0.2, min_sample=64, score_with_bad=0.27752247\n",
      "epsilon=0.2, min_sample=66 classification is bad\n",
      "epsilon=0.2, min_sample=66, score_with_bad=0.27811477\n",
      "epsilon=0.2, min_sample=68 classification is bad\n",
      "epsilon=0.2, min_sample=68, score_with_bad=0.27804843\n",
      "epsilon=0.2, min_sample=70 classification is bad\n",
      "epsilon=0.2, min_sample=70, score_with_bad=0.27724984\n",
      "epsilon=0.2, min_sample=72 classification is bad\n",
      "epsilon=0.2, min_sample=72, score_with_bad=0.27714577\n",
      "epsilon=0.2, min_sample=74 classification is bad\n",
      "epsilon=0.2, min_sample=74, score_with_bad=0.27714577\n",
      "epsilon=0.2, min_sample=76 classification is bad\n",
      "epsilon=0.2, min_sample=76, score_with_bad=0.27714577\n",
      "epsilon=0.2, min_sample=78 classification is bad\n",
      "epsilon=0.2, min_sample=78, score_with_bad=0.27711606\n",
      "epsilon=0.2, min_sample=80 classification is bad\n",
      "epsilon=0.2, min_sample=80, score_with_bad=0.27711606\n",
      "epsilon=0.2, min_sample=82 classification is bad\n",
      "epsilon=0.2, min_sample=82, score_with_bad=0.27711606\n",
      "epsilon=0.2, min_sample=84 classification is bad\n",
      "epsilon=0.2, min_sample=84, score_with_bad=0.27711606\n",
      "epsilon=0.2, min_sample=86 classification is bad\n",
      "epsilon=0.2, min_sample=86, score_with_bad=0.27737108\n",
      "epsilon=0.2, min_sample=88 classification is bad\n",
      "epsilon=0.2, min_sample=88, score_with_bad=0.27737108\n",
      "epsilon=0.2, min_sample=90 classification is bad\n",
      "epsilon=0.2, min_sample=90, score_with_bad=0.2788831\n",
      "epsilon=0.2, min_sample=92 classification is bad\n",
      "epsilon=0.2, min_sample=92, score_with_bad=0.2788831\n",
      "epsilon=0.2, min_sample=94 classification is bad\n",
      "epsilon=0.2, min_sample=94, score_with_bad=0.27814442\n",
      "epsilon=0.2, min_sample=96 classification is bad\n",
      "epsilon=0.2, min_sample=96, score_with_bad=0.27814442\n",
      "epsilon=0.2, min_sample=98 classification is bad\n",
      "epsilon=0.2, min_sample=98, score_with_bad=0.27874723\n",
      "epsilon=0.2, min_sample=100 classification is bad\n",
      "epsilon=0.2, min_sample=100, score_with_bad=0.2782856\n",
      "epsilon=0.25, min_sample=2 classification is bad\n",
      "epsilon=0.25, min_sample=2, score_with_bad=0.33899623\n",
      "epsilon=0.25, min_sample=4 classification is bad\n",
      "epsilon=0.25, min_sample=4, score_with_bad=0.33899623\n",
      "epsilon=0.25, min_sample=6 classification is bad\n",
      "epsilon=0.25, min_sample=6, score_with_bad=0.33899623\n",
      "epsilon=0.25, min_sample=8 classification is bad\n",
      "epsilon=0.25, min_sample=8, score_with_bad=0.33899623\n",
      "epsilon=0.25, min_sample=10 classification is bad\n",
      "epsilon=0.25, min_sample=10, score_with_bad=0.3206692\n",
      "epsilon=0.25, min_sample=12 classification is bad\n",
      "epsilon=0.25, min_sample=12, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=14 classification is bad\n",
      "epsilon=0.25, min_sample=14, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=16 classification is bad\n",
      "epsilon=0.25, min_sample=16, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=18 classification is bad\n",
      "epsilon=0.25, min_sample=18, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=20 classification is bad\n",
      "epsilon=0.25, min_sample=20, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=22 classification is bad\n",
      "epsilon=0.25, min_sample=22, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=24 classification is bad\n",
      "epsilon=0.25, min_sample=24, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=26 classification is bad\n",
      "epsilon=0.25, min_sample=26, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=28 classification is bad\n",
      "epsilon=0.25, min_sample=28, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=30 classification is bad\n",
      "epsilon=0.25, min_sample=30, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=32 classification is bad\n",
      "epsilon=0.25, min_sample=32, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=34 classification is bad\n",
      "epsilon=0.25, min_sample=34, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=36 classification is bad\n",
      "epsilon=0.25, min_sample=36, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=38 classification is bad\n",
      "epsilon=0.25, min_sample=38, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=40 classification is bad\n",
      "epsilon=0.25, min_sample=40, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=42 classification is bad\n",
      "epsilon=0.25, min_sample=42, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=44 classification is bad\n",
      "epsilon=0.25, min_sample=44, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=46 classification is bad\n",
      "epsilon=0.25, min_sample=46, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=48 classification is bad\n",
      "epsilon=0.25, min_sample=48, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=50 classification is bad\n",
      "epsilon=0.25, min_sample=50, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=52 classification is bad\n",
      "epsilon=0.25, min_sample=52, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=54 classification is bad\n",
      "epsilon=0.25, min_sample=54, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=56 classification is bad\n",
      "epsilon=0.25, min_sample=56, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=58 classification is bad\n",
      "epsilon=0.25, min_sample=58, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=60 classification is bad\n",
      "epsilon=0.25, min_sample=60, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=62 classification is bad\n",
      "epsilon=0.25, min_sample=62, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=64 classification is bad\n",
      "epsilon=0.25, min_sample=64, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=66 classification is bad\n",
      "epsilon=0.25, min_sample=66, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=68 classification is bad\n",
      "epsilon=0.25, min_sample=68, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=70 classification is bad\n",
      "epsilon=0.25, min_sample=70, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=72 classification is bad\n",
      "epsilon=0.25, min_sample=72, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=74 classification is bad\n",
      "epsilon=0.25, min_sample=74, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=76 classification is bad\n",
      "epsilon=0.25, min_sample=76, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=78 classification is bad\n",
      "epsilon=0.25, min_sample=78, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=80 classification is bad\n",
      "epsilon=0.25, min_sample=80, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=82 classification is bad\n",
      "epsilon=0.25, min_sample=82, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=84 classification is bad\n",
      "epsilon=0.25, min_sample=84, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=86 classification is bad\n",
      "epsilon=0.25, min_sample=86, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=88 classification is bad\n",
      "epsilon=0.25, min_sample=88, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=90 classification is bad\n",
      "epsilon=0.25, min_sample=90, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=92 classification is bad\n",
      "epsilon=0.25, min_sample=92, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=94 classification is bad\n",
      "epsilon=0.25, min_sample=94, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=96 classification is bad\n",
      "epsilon=0.25, min_sample=96, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=98 classification is bad\n",
      "epsilon=0.25, min_sample=98, score_with_bad=0.3222414\n",
      "epsilon=0.25, min_sample=100 classification is bad\n",
      "epsilon=0.25, min_sample=100, score_with_bad=0.3222414\n",
      "epsilon=0.3, min_sample=2 classification is bad\n",
      "epsilon=0.3, min_sample=2, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=4 classification is bad\n",
      "epsilon=0.3, min_sample=4, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=6 classification is bad\n",
      "epsilon=0.3, min_sample=6, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=8 classification is bad\n",
      "epsilon=0.3, min_sample=8, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=10 classification is bad\n",
      "epsilon=0.3, min_sample=10, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=12 classification is bad\n",
      "epsilon=0.3, min_sample=12, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=14 classification is bad\n",
      "epsilon=0.3, min_sample=14, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=16 classification is bad\n",
      "epsilon=0.3, min_sample=16, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=18 classification is bad\n",
      "epsilon=0.3, min_sample=18, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=20 classification is bad\n",
      "epsilon=0.3, min_sample=20, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=22 classification is bad\n",
      "epsilon=0.3, min_sample=22, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=24 classification is bad\n",
      "epsilon=0.3, min_sample=24, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=26 classification is bad\n",
      "epsilon=0.3, min_sample=26, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=28 classification is bad\n",
      "epsilon=0.3, min_sample=28, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=30 classification is bad\n",
      "epsilon=0.3, min_sample=30, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=32 classification is bad\n",
      "epsilon=0.3, min_sample=32, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=34 classification is bad\n",
      "epsilon=0.3, min_sample=34, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=36 classification is bad\n",
      "epsilon=0.3, min_sample=36, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=38 classification is bad\n",
      "epsilon=0.3, min_sample=38, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=40 classification is bad\n",
      "epsilon=0.3, min_sample=40, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=42 classification is bad\n",
      "epsilon=0.3, min_sample=42, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=44 classification is bad\n",
      "epsilon=0.3, min_sample=44, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=46 classification is bad\n",
      "epsilon=0.3, min_sample=46, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=48 classification is bad\n",
      "epsilon=0.3, min_sample=48, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=50 classification is bad\n",
      "epsilon=0.3, min_sample=50, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=52 classification is bad\n",
      "epsilon=0.3, min_sample=52, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=54 classification is bad\n",
      "epsilon=0.3, min_sample=54, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=56 classification is bad\n",
      "epsilon=0.3, min_sample=56, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=58 classification is bad\n",
      "epsilon=0.3, min_sample=58, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=60 classification is bad\n",
      "epsilon=0.3, min_sample=60, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=62 classification is bad\n",
      "epsilon=0.3, min_sample=62, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=64 classification is bad\n",
      "epsilon=0.3, min_sample=64, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=66 classification is bad\n",
      "epsilon=0.3, min_sample=66, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=68 classification is bad\n",
      "epsilon=0.3, min_sample=68, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=70 classification is bad\n",
      "epsilon=0.3, min_sample=70, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=72 classification is bad\n",
      "epsilon=0.3, min_sample=72, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=74 classification is bad\n",
      "epsilon=0.3, min_sample=74, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=76 classification is bad\n",
      "epsilon=0.3, min_sample=76, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=78 classification is bad\n",
      "epsilon=0.3, min_sample=78, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=80 classification is bad\n",
      "epsilon=0.3, min_sample=80, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=82 classification is bad\n",
      "epsilon=0.3, min_sample=82, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=84 classification is bad\n",
      "epsilon=0.3, min_sample=84, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=86 classification is bad\n",
      "epsilon=0.3, min_sample=86, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=88 classification is bad\n",
      "epsilon=0.3, min_sample=88, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=90 classification is bad\n",
      "epsilon=0.3, min_sample=90, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=92 classification is bad\n",
      "epsilon=0.3, min_sample=92, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=94 classification is bad\n",
      "epsilon=0.3, min_sample=94, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=96 classification is bad\n",
      "epsilon=0.3, min_sample=96, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=98 classification is bad\n",
      "epsilon=0.3, min_sample=98, score_with_bad=0.33899623\n",
      "epsilon=0.3, min_sample=100 classification is bad\n",
      "epsilon=0.3, min_sample=100, score_with_bad=0.33899623\n",
      "epsilon=0.35000000000000003, min_sample=2 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=4 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=6 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=8 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=10 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=12 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=14 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=16 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=18 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=20 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=22 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=24 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=26 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=28 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=30 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=32 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=34 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=36 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=38 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=40 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=42 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=44 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=46 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=48 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=50 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=52 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=54 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=56 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=58 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=60 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=62 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=64 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=66 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=68 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=70 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=72 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=74 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=76 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=78 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=80 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=82 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=84 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=86 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=88 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=90 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=92 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=94 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=96 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=98 classification is very bad\n",
      "epsilon=0.35000000000000003, min_sample=100 classification is very bad\n",
      "epsilon=0.4, min_sample=2 classification is very bad\n",
      "epsilon=0.4, min_sample=4 classification is very bad\n",
      "epsilon=0.4, min_sample=6 classification is very bad\n",
      "epsilon=0.4, min_sample=8 classification is very bad\n",
      "epsilon=0.4, min_sample=10 classification is very bad\n",
      "epsilon=0.4, min_sample=12 classification is very bad\n",
      "epsilon=0.4, min_sample=14 classification is very bad\n",
      "epsilon=0.4, min_sample=16 classification is very bad\n",
      "epsilon=0.4, min_sample=18 classification is very bad\n",
      "epsilon=0.4, min_sample=20 classification is very bad\n",
      "epsilon=0.4, min_sample=22 classification is very bad\n",
      "epsilon=0.4, min_sample=24 classification is very bad\n",
      "epsilon=0.4, min_sample=26 classification is very bad\n",
      "epsilon=0.4, min_sample=28 classification is very bad\n",
      "epsilon=0.4, min_sample=30 classification is very bad\n",
      "epsilon=0.4, min_sample=32 classification is very bad\n",
      "epsilon=0.4, min_sample=34 classification is very bad\n",
      "epsilon=0.4, min_sample=36 classification is very bad\n",
      "epsilon=0.4, min_sample=38 classification is very bad\n",
      "epsilon=0.4, min_sample=40 classification is very bad\n",
      "epsilon=0.4, min_sample=42 classification is very bad\n",
      "epsilon=0.4, min_sample=44 classification is very bad\n",
      "epsilon=0.4, min_sample=46 classification is very bad\n",
      "epsilon=0.4, min_sample=48 classification is very bad\n",
      "epsilon=0.4, min_sample=50 classification is very bad\n",
      "epsilon=0.4, min_sample=52 classification is very bad\n",
      "epsilon=0.4, min_sample=54 classification is very bad\n",
      "epsilon=0.4, min_sample=56 classification is very bad\n",
      "epsilon=0.4, min_sample=58 classification is very bad\n",
      "epsilon=0.4, min_sample=60 classification is very bad\n",
      "epsilon=0.4, min_sample=62 classification is very bad\n",
      "epsilon=0.4, min_sample=64 classification is very bad\n",
      "epsilon=0.4, min_sample=66 classification is very bad\n",
      "epsilon=0.4, min_sample=68 classification is very bad\n",
      "epsilon=0.4, min_sample=70 classification is very bad\n",
      "epsilon=0.4, min_sample=72 classification is very bad\n",
      "epsilon=0.4, min_sample=74 classification is very bad\n",
      "epsilon=0.4, min_sample=76 classification is very bad\n",
      "epsilon=0.4, min_sample=78 classification is very bad\n",
      "epsilon=0.4, min_sample=80 classification is very bad\n",
      "epsilon=0.4, min_sample=82 classification is very bad\n",
      "epsilon=0.4, min_sample=84 classification is very bad\n",
      "epsilon=0.4, min_sample=86 classification is very bad\n",
      "epsilon=0.4, min_sample=88 classification is very bad\n",
      "epsilon=0.4, min_sample=90 classification is very bad\n",
      "epsilon=0.4, min_sample=92 classification is very bad\n",
      "epsilon=0.4, min_sample=94 classification is very bad\n",
      "epsilon=0.4, min_sample=96 classification is very bad\n",
      "epsilon=0.4, min_sample=98 classification is very bad\n",
      "epsilon=0.4, min_sample=100 classification is very bad\n",
      "epsilon=0.45, min_sample=2 classification is very bad\n",
      "epsilon=0.45, min_sample=4 classification is very bad\n",
      "epsilon=0.45, min_sample=6 classification is very bad\n",
      "epsilon=0.45, min_sample=8 classification is very bad\n",
      "epsilon=0.45, min_sample=10 classification is very bad\n",
      "epsilon=0.45, min_sample=12 classification is very bad\n",
      "epsilon=0.45, min_sample=14 classification is very bad\n",
      "epsilon=0.45, min_sample=16 classification is very bad\n",
      "epsilon=0.45, min_sample=18 classification is very bad\n",
      "epsilon=0.45, min_sample=20 classification is very bad\n",
      "epsilon=0.45, min_sample=22 classification is very bad\n",
      "epsilon=0.45, min_sample=24 classification is very bad\n",
      "epsilon=0.45, min_sample=26 classification is very bad\n",
      "epsilon=0.45, min_sample=28 classification is very bad\n",
      "epsilon=0.45, min_sample=30 classification is very bad\n",
      "epsilon=0.45, min_sample=32 classification is very bad\n",
      "epsilon=0.45, min_sample=34 classification is very bad\n",
      "epsilon=0.45, min_sample=36 classification is very bad\n",
      "epsilon=0.45, min_sample=38 classification is very bad\n",
      "epsilon=0.45, min_sample=40 classification is very bad\n",
      "epsilon=0.45, min_sample=42 classification is very bad\n",
      "epsilon=0.45, min_sample=44 classification is very bad\n",
      "epsilon=0.45, min_sample=46 classification is very bad\n",
      "epsilon=0.45, min_sample=48 classification is very bad\n",
      "epsilon=0.45, min_sample=50 classification is very bad\n",
      "epsilon=0.45, min_sample=52 classification is very bad\n",
      "epsilon=0.45, min_sample=54 classification is very bad\n",
      "epsilon=0.45, min_sample=56 classification is very bad\n",
      "epsilon=0.45, min_sample=58 classification is very bad\n",
      "epsilon=0.45, min_sample=60 classification is very bad\n",
      "epsilon=0.45, min_sample=62 classification is very bad\n",
      "epsilon=0.45, min_sample=64 classification is very bad\n",
      "epsilon=0.45, min_sample=66 classification is very bad\n",
      "epsilon=0.45, min_sample=68 classification is very bad\n",
      "epsilon=0.45, min_sample=70 classification is very bad\n",
      "epsilon=0.45, min_sample=72 classification is very bad\n",
      "epsilon=0.45, min_sample=74 classification is very bad\n",
      "epsilon=0.45, min_sample=76 classification is very bad\n",
      "epsilon=0.45, min_sample=78 classification is very bad\n",
      "epsilon=0.45, min_sample=80 classification is very bad\n",
      "epsilon=0.45, min_sample=82 classification is very bad\n",
      "epsilon=0.45, min_sample=84 classification is very bad\n",
      "epsilon=0.45, min_sample=86 classification is very bad\n",
      "epsilon=0.45, min_sample=88 classification is very bad\n",
      "epsilon=0.45, min_sample=90 classification is very bad\n",
      "epsilon=0.45, min_sample=92 classification is very bad\n",
      "epsilon=0.45, min_sample=94 classification is very bad\n",
      "epsilon=0.45, min_sample=96 classification is very bad\n",
      "epsilon=0.45, min_sample=98 classification is very bad\n",
      "epsilon=0.45, min_sample=100 classification is very bad\n",
      "epsilon=0.5, min_sample=2 classification is very bad\n",
      "epsilon=0.5, min_sample=4 classification is very bad\n",
      "epsilon=0.5, min_sample=6 classification is very bad\n",
      "epsilon=0.5, min_sample=8 classification is very bad\n",
      "epsilon=0.5, min_sample=10 classification is very bad\n",
      "epsilon=0.5, min_sample=12 classification is very bad\n",
      "epsilon=0.5, min_sample=14 classification is very bad\n",
      "epsilon=0.5, min_sample=16 classification is very bad\n",
      "epsilon=0.5, min_sample=18 classification is very bad\n",
      "epsilon=0.5, min_sample=20 classification is very bad\n",
      "epsilon=0.5, min_sample=22 classification is very bad\n",
      "epsilon=0.5, min_sample=24 classification is very bad\n",
      "epsilon=0.5, min_sample=26 classification is very bad\n",
      "epsilon=0.5, min_sample=28 classification is very bad\n",
      "epsilon=0.5, min_sample=30 classification is very bad\n",
      "epsilon=0.5, min_sample=32 classification is very bad\n",
      "epsilon=0.5, min_sample=34 classification is very bad\n",
      "epsilon=0.5, min_sample=36 classification is very bad\n",
      "epsilon=0.5, min_sample=38 classification is very bad\n",
      "epsilon=0.5, min_sample=40 classification is very bad\n",
      "epsilon=0.5, min_sample=42 classification is very bad\n",
      "epsilon=0.5, min_sample=44 classification is very bad\n",
      "epsilon=0.5, min_sample=46 classification is very bad\n",
      "epsilon=0.5, min_sample=48 classification is very bad\n",
      "epsilon=0.5, min_sample=50 classification is very bad\n",
      "epsilon=0.5, min_sample=52 classification is very bad\n",
      "epsilon=0.5, min_sample=54 classification is very bad\n",
      "epsilon=0.5, min_sample=56 classification is very bad\n",
      "epsilon=0.5, min_sample=58 classification is very bad\n",
      "epsilon=0.5, min_sample=60 classification is very bad\n",
      "epsilon=0.5, min_sample=62 classification is very bad\n",
      "epsilon=0.5, min_sample=64 classification is very bad\n",
      "epsilon=0.5, min_sample=66 classification is very bad\n",
      "epsilon=0.5, min_sample=68 classification is very bad\n",
      "epsilon=0.5, min_sample=70 classification is very bad\n",
      "epsilon=0.5, min_sample=72 classification is very bad\n",
      "epsilon=0.5, min_sample=74 classification is very bad\n",
      "epsilon=0.5, min_sample=76 classification is very bad\n",
      "epsilon=0.5, min_sample=78 classification is very bad\n",
      "epsilon=0.5, min_sample=80 classification is very bad\n",
      "epsilon=0.5, min_sample=82 classification is very bad\n",
      "epsilon=0.5, min_sample=84 classification is very bad\n",
      "epsilon=0.5, min_sample=86 classification is very bad\n",
      "epsilon=0.5, min_sample=88 classification is very bad\n",
      "epsilon=0.5, min_sample=90 classification is very bad\n",
      "epsilon=0.5, min_sample=92 classification is very bad\n",
      "epsilon=0.5, min_sample=94 classification is very bad\n",
      "epsilon=0.5, min_sample=96 classification is very bad\n",
      "epsilon=0.5, min_sample=98 classification is very bad\n",
      "epsilon=0.5, min_sample=100 classification is very bad\n",
      "epsilon=0.55, min_sample=2 classification is very bad\n",
      "epsilon=0.55, min_sample=4 classification is very bad\n",
      "epsilon=0.55, min_sample=6 classification is very bad\n",
      "epsilon=0.55, min_sample=8 classification is very bad\n",
      "epsilon=0.55, min_sample=10 classification is very bad\n",
      "epsilon=0.55, min_sample=12 classification is very bad\n",
      "epsilon=0.55, min_sample=14 classification is very bad\n",
      "epsilon=0.55, min_sample=16 classification is very bad\n",
      "epsilon=0.55, min_sample=18 classification is very bad\n",
      "epsilon=0.55, min_sample=20 classification is very bad\n",
      "epsilon=0.55, min_sample=22 classification is very bad\n",
      "epsilon=0.55, min_sample=24 classification is very bad\n",
      "epsilon=0.55, min_sample=26 classification is very bad\n",
      "epsilon=0.55, min_sample=28 classification is very bad\n",
      "epsilon=0.55, min_sample=30 classification is very bad\n",
      "epsilon=0.55, min_sample=32 classification is very bad\n",
      "epsilon=0.55, min_sample=34 classification is very bad\n",
      "epsilon=0.55, min_sample=36 classification is very bad\n",
      "epsilon=0.55, min_sample=38 classification is very bad\n",
      "epsilon=0.55, min_sample=40 classification is very bad\n",
      "epsilon=0.55, min_sample=42 classification is very bad\n",
      "epsilon=0.55, min_sample=44 classification is very bad\n",
      "epsilon=0.55, min_sample=46 classification is very bad\n",
      "epsilon=0.55, min_sample=48 classification is very bad\n",
      "epsilon=0.55, min_sample=50 classification is very bad\n",
      "epsilon=0.55, min_sample=52 classification is very bad\n",
      "epsilon=0.55, min_sample=54 classification is very bad\n",
      "epsilon=0.55, min_sample=56 classification is very bad\n",
      "epsilon=0.55, min_sample=58 classification is very bad\n",
      "epsilon=0.55, min_sample=60 classification is very bad\n",
      "epsilon=0.55, min_sample=62 classification is very bad\n",
      "epsilon=0.55, min_sample=64 classification is very bad\n",
      "epsilon=0.55, min_sample=66 classification is very bad\n",
      "epsilon=0.55, min_sample=68 classification is very bad\n",
      "epsilon=0.55, min_sample=70 classification is very bad\n",
      "epsilon=0.55, min_sample=72 classification is very bad\n",
      "epsilon=0.55, min_sample=74 classification is very bad\n",
      "epsilon=0.55, min_sample=76 classification is very bad\n",
      "epsilon=0.55, min_sample=78 classification is very bad\n",
      "epsilon=0.55, min_sample=80 classification is very bad\n",
      "epsilon=0.55, min_sample=82 classification is very bad\n",
      "epsilon=0.55, min_sample=84 classification is very bad\n",
      "epsilon=0.55, min_sample=86 classification is very bad\n",
      "epsilon=0.55, min_sample=88 classification is very bad\n",
      "epsilon=0.55, min_sample=90 classification is very bad\n",
      "epsilon=0.55, min_sample=92 classification is very bad\n",
      "epsilon=0.55, min_sample=94 classification is very bad\n",
      "epsilon=0.55, min_sample=96 classification is very bad\n",
      "epsilon=0.55, min_sample=98 classification is very bad\n",
      "epsilon=0.55, min_sample=100 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.6000000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.6500000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.7000000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.7500000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.8, min_sample=2 classification is very bad\n",
      "epsilon=0.8, min_sample=4 classification is very bad\n",
      "epsilon=0.8, min_sample=6 classification is very bad\n",
      "epsilon=0.8, min_sample=8 classification is very bad\n",
      "epsilon=0.8, min_sample=10 classification is very bad\n",
      "epsilon=0.8, min_sample=12 classification is very bad\n",
      "epsilon=0.8, min_sample=14 classification is very bad\n",
      "epsilon=0.8, min_sample=16 classification is very bad\n",
      "epsilon=0.8, min_sample=18 classification is very bad\n",
      "epsilon=0.8, min_sample=20 classification is very bad\n",
      "epsilon=0.8, min_sample=22 classification is very bad\n",
      "epsilon=0.8, min_sample=24 classification is very bad\n",
      "epsilon=0.8, min_sample=26 classification is very bad\n",
      "epsilon=0.8, min_sample=28 classification is very bad\n",
      "epsilon=0.8, min_sample=30 classification is very bad\n",
      "epsilon=0.8, min_sample=32 classification is very bad\n",
      "epsilon=0.8, min_sample=34 classification is very bad\n",
      "epsilon=0.8, min_sample=36 classification is very bad\n",
      "epsilon=0.8, min_sample=38 classification is very bad\n",
      "epsilon=0.8, min_sample=40 classification is very bad\n",
      "epsilon=0.8, min_sample=42 classification is very bad\n",
      "epsilon=0.8, min_sample=44 classification is very bad\n",
      "epsilon=0.8, min_sample=46 classification is very bad\n",
      "epsilon=0.8, min_sample=48 classification is very bad\n",
      "epsilon=0.8, min_sample=50 classification is very bad\n",
      "epsilon=0.8, min_sample=52 classification is very bad\n",
      "epsilon=0.8, min_sample=54 classification is very bad\n",
      "epsilon=0.8, min_sample=56 classification is very bad\n",
      "epsilon=0.8, min_sample=58 classification is very bad\n",
      "epsilon=0.8, min_sample=60 classification is very bad\n",
      "epsilon=0.8, min_sample=62 classification is very bad\n",
      "epsilon=0.8, min_sample=64 classification is very bad\n",
      "epsilon=0.8, min_sample=66 classification is very bad\n",
      "epsilon=0.8, min_sample=68 classification is very bad\n",
      "epsilon=0.8, min_sample=70 classification is very bad\n",
      "epsilon=0.8, min_sample=72 classification is very bad\n",
      "epsilon=0.8, min_sample=74 classification is very bad\n",
      "epsilon=0.8, min_sample=76 classification is very bad\n",
      "epsilon=0.8, min_sample=78 classification is very bad\n",
      "epsilon=0.8, min_sample=80 classification is very bad\n",
      "epsilon=0.8, min_sample=82 classification is very bad\n",
      "epsilon=0.8, min_sample=84 classification is very bad\n",
      "epsilon=0.8, min_sample=86 classification is very bad\n",
      "epsilon=0.8, min_sample=88 classification is very bad\n",
      "epsilon=0.8, min_sample=90 classification is very bad\n",
      "epsilon=0.8, min_sample=92 classification is very bad\n",
      "epsilon=0.8, min_sample=94 classification is very bad\n",
      "epsilon=0.8, min_sample=96 classification is very bad\n",
      "epsilon=0.8, min_sample=98 classification is very bad\n",
      "epsilon=0.8, min_sample=100 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.8500000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.9000000000000001, min_sample=100 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=2 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=4 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=6 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=8 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=10 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=12 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=14 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=16 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=18 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=20 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=22 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=24 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=26 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=28 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=30 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=32 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=34 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=36 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=38 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=40 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=42 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=44 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=46 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=48 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=50 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=52 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=54 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=56 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=58 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=60 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=62 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=64 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=66 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=68 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=70 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=72 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=74 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=76 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=78 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=80 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=82 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=84 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=86 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=88 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=90 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=92 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=94 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=96 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=98 classification is very bad\n",
      "epsilon=0.9500000000000001, min_sample=100 classification is very bad\n",
      "epsilon=1.0, min_sample=2 classification is very bad\n",
      "epsilon=1.0, min_sample=4 classification is very bad\n",
      "epsilon=1.0, min_sample=6 classification is very bad\n",
      "epsilon=1.0, min_sample=8 classification is very bad\n",
      "epsilon=1.0, min_sample=10 classification is very bad\n",
      "epsilon=1.0, min_sample=12 classification is very bad\n",
      "epsilon=1.0, min_sample=14 classification is very bad\n",
      "epsilon=1.0, min_sample=16 classification is very bad\n",
      "epsilon=1.0, min_sample=18 classification is very bad\n",
      "epsilon=1.0, min_sample=20 classification is very bad\n",
      "epsilon=1.0, min_sample=22 classification is very bad\n",
      "epsilon=1.0, min_sample=24 classification is very bad\n",
      "epsilon=1.0, min_sample=26 classification is very bad\n",
      "epsilon=1.0, min_sample=28 classification is very bad\n",
      "epsilon=1.0, min_sample=30 classification is very bad\n",
      "epsilon=1.0, min_sample=32 classification is very bad\n",
      "epsilon=1.0, min_sample=34 classification is very bad\n",
      "epsilon=1.0, min_sample=36 classification is very bad\n",
      "epsilon=1.0, min_sample=38 classification is very bad\n",
      "epsilon=1.0, min_sample=40 classification is very bad\n",
      "epsilon=1.0, min_sample=42 classification is very bad\n",
      "epsilon=1.0, min_sample=44 classification is very bad\n",
      "epsilon=1.0, min_sample=46 classification is very bad\n",
      "epsilon=1.0, min_sample=48 classification is very bad\n",
      "epsilon=1.0, min_sample=50 classification is very bad\n",
      "epsilon=1.0, min_sample=52 classification is very bad\n",
      "epsilon=1.0, min_sample=54 classification is very bad\n",
      "epsilon=1.0, min_sample=56 classification is very bad\n",
      "epsilon=1.0, min_sample=58 classification is very bad\n",
      "epsilon=1.0, min_sample=60 classification is very bad\n",
      "epsilon=1.0, min_sample=62 classification is very bad\n",
      "epsilon=1.0, min_sample=64 classification is very bad\n",
      "epsilon=1.0, min_sample=66 classification is very bad\n",
      "epsilon=1.0, min_sample=68 classification is very bad\n",
      "epsilon=1.0, min_sample=70 classification is very bad\n",
      "epsilon=1.0, min_sample=72 classification is very bad\n",
      "epsilon=1.0, min_sample=74 classification is very bad\n",
      "epsilon=1.0, min_sample=76 classification is very bad\n",
      "epsilon=1.0, min_sample=78 classification is very bad\n",
      "epsilon=1.0, min_sample=80 classification is very bad\n",
      "epsilon=1.0, min_sample=82 classification is very bad\n",
      "epsilon=1.0, min_sample=84 classification is very bad\n",
      "epsilon=1.0, min_sample=86 classification is very bad\n",
      "epsilon=1.0, min_sample=88 classification is very bad\n",
      "epsilon=1.0, min_sample=90 classification is very bad\n",
      "epsilon=1.0, min_sample=92 classification is very bad\n",
      "epsilon=1.0, min_sample=94 classification is very bad\n",
      "epsilon=1.0, min_sample=96 classification is very bad\n",
      "epsilon=1.0, min_sample=98 classification is very bad\n",
      "epsilon=1.0, min_sample=100 classification is very bad\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgower_matrix.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:429\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import gower\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "new_df: pd.DataFrame = X\n",
    "\n",
    "new_df = new_df[~new_df.eq(\"?\").any(axis=1)]\n",
    "new_df = new_df.dropna().reset_index(drop=True)\n",
    "mini_df = new_df.sample(10000)\n",
    "\n",
    "gower_dist = gower.gower_matrix(mini_df)\n",
    "full_results = []\n",
    "\n",
    "epsilon_values = np.arange(0.05, 1.05, 0.05)\n",
    "min_samples_values = range(2, 101, 2)\n",
    "\n",
    "max_score = -1\n",
    "# Run DBSCAN on the Gower distance matrix\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    for min_sample in min_samples_values:\n",
    "        dbscan = DBSCAN(metric='precomputed', eps=epsilon, min_samples=min_sample)\n",
    "        labels = dbscan.fit_predict(gower_dist)\n",
    "        number_of_labels = len(set(labels))\n",
    "        if ({-1, 0} == set(labels)):\n",
    "            print(f\"{epsilon=}, {min_sample=} classification is bad\")\n",
    "            score_with_bad = silhouette_score(gower_dist, labels, metric='precomputed')\n",
    "            print(f\"{epsilon=}, {min_sample=}, {score_with_bad=}\")\n",
    "            continue\n",
    "        if number_of_labels == 1:\n",
    "            print(f\"{epsilon=}, {min_sample=} classification is very bad\")\n",
    "            continue\n",
    "\n",
    "        mask = labels != -1\n",
    "        try:\n",
    "        # Compute silhouette score only on non-noise points\n",
    "            score_without_bad = silhouette_score(gower_dist[mask][:, mask], labels[mask], metric='precomputed')\n",
    "            score_with_bad = silhouette_score(gower_dist, labels, metric='precomputed')\n",
    "        except Exception as e:\n",
    "            import ipdb\n",
    "            ipdb.set_trace()\n",
    "        if score_with_bad >= max_score:\n",
    "            max_score = score_with_bad\n",
    "            print(f\"{epsilon=}, {min_sample=}, {number_of_labels=}, {score_with_bad=}, {score_without_bad}\")\n",
    "            \n",
    "        full_results.append([epsilon, min_sample, number_of_labels, score_with_bad, score_without_bad])\n",
    "        \n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"gower_matrix_dbscan.pkl\", \"wb\") as f:\n",
    "    pickle.dump(full_results, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3509dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: -0.016717758\n"
     ]
    }
   ],
   "source": [
    "mask = labels != -1\n",
    "\n",
    "# Compute silhouette score only on non-noise points\n",
    "score = silhouette_score(gower_dist[mask][:, mask], labels[mask], metric='precomputed')\n",
    "# score = silhouette_score(gower_dist, labels, metric='precomputed')\n",
    "\n",
    "print(\"Silhouette Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42aff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=0.5839696420851198, n_clusters=2, kproto.cost_=47600340443889.32\n",
      "score=0.5470239186384337, n_clusters=3, kproto.cost_=26250635086135.605\n",
      "score=0.5503478123708605, n_clusters=4, kproto.cost_=17651557379011.86\n",
      "score=0.5309211677627476, n_clusters=5, kproto.cost_=12930092690963.555\n",
      "score=0.5350708561075785, n_clusters=6, kproto.cost_=9669832064624.227\n",
      "score=0.5425061502647003, n_clusters=7, kproto.cost_=7034531985936.423\n",
      "score=0.5285074019016304, n_clusters=8, kproto.cost_=5450677488713.95\n",
      "score=0.5277898745868209, n_clusters=9, kproto.cost_=4397565147883.036\n",
      "score=0.5266726647543968, n_clusters=10, kproto.cost_=3729302490553.4453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_clusters \u001b[38;5;129;01min\u001b[39;00m clusters_range:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# for gamma in gamma_range:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     kproto \u001b[38;5;241m=\u001b[39m KPrototypes(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCao\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m \u001b[43mkproto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     score \u001b[38;5;241m=\u001b[39m silhouette_score(mini_df, clusters)\n\u001b[1;32m     24\u001b[0m     all_scores\u001b[38;5;241m.\u001b[39mappend([n_clusters, score, kproto\u001b[38;5;241m.\u001b[39mcost_])\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/kmodes.py:154\u001b[0m, in \u001b[0;36mKModes.fit_predict\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    149\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centroids and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    predict(X).\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/kprototypes.py:161\u001b[0m, in \u001b[0;36mKPrototypes.fit\u001b[0;34m(self, X, y, categorical, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m kmodes\u001b[38;5;241m.\u001b[39m_validate_sample_weight(sample_weight, n_samples\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    156\u001b[0m                                n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# If self.gamma is None, gamma will be automatically determined from\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# the data. The function below returns its value.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enc_cluster_centroids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enc_map, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_, \\\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_costs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m \u001b[43mk_prototypes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dissim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat_dissim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/kprototypes.py:299\u001b[0m, in \u001b[0;36mk_prototypes\u001b[0;34m(X, categorical, n_clusters, max_iter, num_dissim, cat_dissim, gamma, init, n_init, verbose, random_state, n_jobs, sample_weight)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m init_no \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_init):\n\u001b[0;32m--> 299\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_k_prototypes_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnumattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncatattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mnum_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43minit_no\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(\n\u001b[1;32m    306\u001b[0m         delayed(_k_prototypes_single)(Xnum, Xcat, nnumattrs, ncatattrs,\n\u001b[1;32m    307\u001b[0m                                       n_clusters, n_points, max_iter,\n\u001b[1;32m    308\u001b[0m                                       num_dissim, cat_dissim, gamma,\n\u001b[1;32m    309\u001b[0m                                       init, init_no, verbose, seed, sample_weight)\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m init_no, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seeds))\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/kprototypes.py:441\u001b[0m, in \u001b[0;36m_k_prototypes_single\u001b[0;34m(Xnum, Xcat, nnumattrs, ncatattrs, n_clusters, n_points, max_iter, num_dissim, cat_dissim, gamma, init, init_no, verbose, random_state, sample_weight)\u001b[0m\n\u001b[1;32m    435\u001b[0m centroids, cl_attr_sum, cl_memb_sum, cl_attr_freq, membship, moves \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    436\u001b[0m     _k_prototypes_iter(Xnum, Xcat, centroids, cl_attr_sum, cl_memb_sum,\n\u001b[1;32m    437\u001b[0m                        cl_attr_freq, membship, num_dissim, cat_dissim,\n\u001b[1;32m    438\u001b[0m                        gamma, random_state, sample_weight)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# All points seen in this iteration\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m labels, ncost \u001b[38;5;241m=\u001b[39m \u001b[43mlabels_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_dissim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmembship\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m converged \u001b[38;5;241m=\u001b[39m (moves \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (ncost \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cost)\n\u001b[1;32m    444\u001b[0m epoch_costs\u001b[38;5;241m.\u001b[39mappend(ncost)\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/kprototypes.py:233\u001b[0m, in \u001b[0;36mlabels_cost\u001b[0;34m(Xnum, Xcat, centroids, num_dissim, cat_dissim, gamma, membship, sample_weight)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ipoint \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points):\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;66;03m# Numerical cost = sum of Euclidean distances\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     num_costs \u001b[38;5;241m=\u001b[39m num_dissim(centroids[\u001b[38;5;241m0\u001b[39m], Xnum[ipoint])\n\u001b[0;32m--> 233\u001b[0m     cat_costs \u001b[38;5;241m=\u001b[39m \u001b[43mcat_dissim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXcat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mipoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmembship\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmembship\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# Gamma relates the categorical cost to the numerical cost.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     tot_costs \u001b[38;5;241m=\u001b[39m num_costs \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m cat_costs\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/kmodes/util/dissim.py:10\u001b[0m, in \u001b[0;36mmatching_dissim\u001b[0;34m(a, b, **_)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmatching_dissim\u001b[39m(a, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simple matching dissimilarity function\"\"\"\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/university/unsupervised_learning_project/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2172\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \n\u001b[1;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2173\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2179\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of potential clusters and gamma values\n",
    "clusters_range = range(2,15)\n",
    "gamma_range = np.linspace(0.1, 1, 10) # gamma values between 0.1 and 1\n",
    "\n",
    "# Placeholder variables\n",
    "best_score = -1\n",
    "best_clusters = None\n",
    "best_labels = None\n",
    "best_gamma = None\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "mini_df = df.sample(10000)\n",
    "\n",
    "for n_clusters in clusters_range:\n",
    "    # for gamma in gamma_range:\n",
    "    kproto = KPrototypes(n_clusters=n_clusters, init='Cao')\n",
    "    clusters = kproto.fit_predict(mini_df, categorical=categorical_indexes)\n",
    "    score = silhouette_score(mini_df, clusters)\n",
    "    all_scores.append([n_clusters, score, kproto.cost_])\n",
    "\n",
    "    # Check if this configuration beats the best score\n",
    "    print(f\"{score=}, {n_clusters=}, {kproto.cost_=}\")\n",
    "    if score > best_score:\n",
    "        best_labels = clusters\n",
    "        best_score = score\n",
    "        best_clusters = n_clusters\n",
    "        # best_gamma = gamma\n",
    "\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(f\"Optimal number of clusters: {best_clusters}\")\n",
    "print(f\"Optimal gamma value: {best_gamma}\")\n",
    "print(f\"{all_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb96e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=53, perplexity=50)\n",
    "tsne_on_df = tsne.fit_transform(mini_df)\n",
    "\n",
    "def plot_tsne(X_tsne, title):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y_sample, palette='viridis', s=50)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend(title='Income')\n",
    "    plt.show()\n",
    "\n",
    "# Visualizations\n",
    "plot_tsne(X_tsne_pca, 't-SNE on PCA-Reduced Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
